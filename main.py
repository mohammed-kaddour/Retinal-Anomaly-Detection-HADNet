import os
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split

# --- IMPORTS SYNCHRONISÃ‰S AVEC L'AUDIT ---
from data.dataset import HybridAnomalyDataset
from models.had_net import HybridAnomalyNet
from utils.training import init_center, train_one_epoch  # Assure-toi que le fichier est utils/training.py

# --- 1. CONFIGURATION ---
# These files are generated by scripts/prepare_data.py
DATA_CSV = "processed_data/processed_metadata.csv"
FEATURES_NPY = "processed_data/texture_features.npy"
BATCH_SIZE = 32
EPOCHS = 50
LEARNING_RATE = 0.001
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def main():
    print(f"[*] Starting HAD-Net Training Pipeline on {DEVICE}...")

    # --- 2. DATA LOADING ---
    if not os.path.exists(DATA_CSV) or not os.path.exists(FEATURES_NPY):
        print("[!] Error: Processed data not found. Please run 'python scripts/prepare_data.py' first.")
        return

    df = pd.read_csv(DATA_CSV)
    features = np.load(FEATURES_NPY)

    # Filter only Healthy samples for Unsupervised Training
    train_df = df[df['anomaly_label'] == 0].reset_index(drop=True)
    train_features = features[df['anomaly_label'] == 0]

    # Split for internal validation
    X_train_df, X_val_df, feat_train, feat_val = train_test_split(
        train_df, train_features, test_size=0.2, random_state=42
    )

    # --- 3. TRANSFORMS & DATALOADERS ---
    data_transforms = transforms.Compose([
        transforms.ToPILImage(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    train_dataset = HybridAnomalyDataset(X_train_df, feat_train, transform=data_transforms)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

    # --- 4. MODEL & OPTIMIZER ---
    model = HybridAnomalyNet(handcrafted_input_size=16, projection_dim=128).to(DEVICE)
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)

    # --- 5. CENTER INITIALIZATION ---
    # We use the initial pass to find the center of normality 'c'
    center = init_center(model, train_loader, DEVICE, is_hybrid=True)
    print(f"[*] Hypersphere center initialized successfully.")

    # --- 6. TRAINING LOOP ---
    train_losses = []
    for epoch in range(EPOCHS):
        loss = train_one_epoch(model, train_loader, center, optimizer, DEVICE, is_hybrid=True)
        train_losses.append(loss)
        
        if (epoch + 1) % 5 == 0:
            print(f"Epoch [{epoch+1}/{EPOCHS}] | Loss: {loss:.4f}")

    # --- 7. SAVING ---
    os.makedirs("weights", exist_ok=True)
    os.makedirs("results", exist_ok=True)
    
    # Save everything needed for evaluation
    torch.save({
        'model_state_dict': model.state_dict(),
        'center': center,
    }, "weights/had_net_final.pth")
    
    # Plot and save loss curve
    plt.plot(train_losses)
    plt.title('Training Loss')
    plt.savefig('results/loss_plot.png')
    
    print("[*] Training finished. Model saved in weights/had_net_final.pth")

if __name__ == "__main__":
    main()
